{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d86ae21d-128d-42f2-b8c7-83b5511a35a2",
   "metadata": {},
   "source": [
    "# Crawling des österreichischen Volleyballteams - Kader Damen\n",
    "\n",
    "## Einführung\n",
    "Im 1. Assignment werden wir Informationen über die Volleyballspielerinnen des österreichischen Nationalteams sammeln. Es existiert eine Liste des Kaders sowie Detailseiten zu jeder Person, in denen die folgenden Daten enthalten sind:\n",
    "- Name\n",
    "- Körpergröße\n",
    "- Dressnummer\n",
    "- Position\n",
    "  \n",
    "Als Ergebnis präsentieren wir ein CSV-File mit den o.g. Datenpunkten und Informationen zu jeder Spielerin des Kaders.\n",
    "\n",
    "Die Umsetzung erfolgt, wie im Assignment vorgegeben, mithilfe der Python-Libraries <i>Selenium</i> und <i>Beautiful Soup 4</i>.\n",
    "\n",
    "## Arbeitsaufteilung\n",
    "**2. Selenium-Crawler auf die Haupt- und Damenkaderseite:** Ecker Annina\n",
    "**3. Laden von Spielerinnen-Daten in einen DataFrame (BeautifulSoup4):** Cesar Laura\n",
    "**4. Abgleich der DFs und Bereinigen der Daten:** Dilly Julian\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a7f04-42a7-4090-acdc-5f4718cbece6",
   "metadata": {},
   "source": [
    "### 1. Installation und Importieren der benötigten Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57d2f66c-101b-40df-b83d-c1e1fa25d0e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install selenium beautifulsoup4 requests pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2787349c-5626-453e-8399-21e4b3111792",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4d0e4-f2d7-4fef-83d8-5be92fc84ab0",
   "metadata": {},
   "source": [
    "### 2. Selenium-Crawler auf die Haupt- und Damenkaderseite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ac06bcb-cb49-4e7a-af0c-3b1f57b48784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cookie-Banner geschlossen\n",
      "✅ Nationalteams Menü gefunden (\u001b[94mNATIONALTEAMS\u001b[0m)\n",
      "✅ Damenkader-Menü gefunden (\u001b[94mDamen\n",
      "Informationen\n",
      "Tickets\u001b[0m)\n",
      "✅ Kader-Link gefunden (\u001b[94mKader\u001b[0m)\n",
      "✅ Aktuelle URL nach dem Klick: \u001b[94mhttps://www.volleynet.at/nationalteams/damen/kader/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Chrome im Headless-Modus starten, da sonst Browser-Fenster aufpoppt\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "base_url = \"https://www.volleynet.at\"\n",
    "\n",
    "# WebDriver starten\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "try:\n",
    "    driver.get(base_url)\n",
    "    # Warten, bis die Seite vollständig geladen ist und Definieren von explizitem Wait\n",
    "    sleep_long = time.sleep(5)\n",
    "    \n",
    "    sleep_long\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "\n",
    "    # Zuerst das Cookie-Banner schließen\n",
    "    try:\n",
    "        cookie_close_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"div.cmplz-close\")))\n",
    "        cookie_close_button.click()\n",
    "        print(\"✅ Cookie-Banner geschlossen\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\033[91m ❌ Cookie-Banner nicht gefunden oder konnte nicht geschlossen werden: {e}\\033[0m\")\n",
    "\n",
    "    # Warte kurz nach dem Schließen des Cookie-Banners\n",
    "    sleep_short = time.sleep(2)\n",
    "    sleep_short\n",
    "\n",
    "    # Navigiere zum Nationalteams-Menü\n",
    "    try:\n",
    "        nationalteams_menu = wait.until(EC.element_to_be_clickable((By.ID, 'menu-item-4424')))\n",
    "        print(f\"✅ Nationalteams Menü gefunden (\\033[94m{nationalteams_menu.text}\\033[0m)\")\n",
    "        \n",
    "        action = ActionChains(driver)\n",
    "        action.move_to_element(nationalteams_menu).perform()\n",
    "        nationalteams_menu.click()\n",
    "        sleep_short\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\033[91m ❌ Fehler beim Navigieren zum Nationalteams-Menü: {e}\\033[0m\")\n",
    "\n",
    "    # Navigiere zum Damenkader-Menü\n",
    "    try:\n",
    "        damen_menu = wait.until(EC.element_to_be_clickable((By.ID, 'menu-item-4434')))\n",
    "        print(f\"✅ Damenkader-Menü gefunden (\\033[94m{damen_menu.text}\\033[0m)\")\n",
    "        sleep_short\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\033[91m ❌ Fehler beim Finden des Damenkader-Menüs: {e}\\033[0m\")\n",
    "\n",
    "    # Selenium soll nun den Kader-Link anklicken\n",
    "    try:\n",
    "        kader_link = wait.until(EC.element_to_be_clickable((By.ID, 'menu-item-4471')))\n",
    "        print(f\"✅ Kader-Link gefunden (\\033[94m{kader_link.text}\\033[0m)\")\n",
    "        \n",
    "        action.move_to_element(kader_link).perform()\n",
    "        kader_link.click()\n",
    "\n",
    "        sleep_long\n",
    "        print(f\"✅ Aktuelle URL nach dem Klick: \\033[94m{driver.current_url}\\033[0m\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\033[91m ❌ Fehler beim Finden oder Klicken auf den Kader-Link: {e}\\033[0m\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\033[91m ❌ Ein allgemeiner Fehler ist aufgetreten: {e}\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dca1c50-fa04-4576-b566-e57b906b845e",
   "metadata": {},
   "source": [
    "### 3. Laden von Spielerinnen-Daten in einen DataFrame (BeautifulSoup4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "064eecd8-977f-4a1f-837b-46c8de0a7ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Player data has been extracted\n",
      "✅ Player data has been saved to 'player_data.csv'\n",
      "✅ Webdriver has been quitted\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # driver.page source is content of current page\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    \n",
    "    # Extract player information\n",
    "    player_table = soup.find(id='DataTables_Table_0')\n",
    "    players = player_table.find_all('tr', class_=['tablehell', 'tabledunkel'])\n",
    "    player_data = []\n",
    "    \n",
    "    for player in players:\n",
    "        try:\n",
    "            dressnumber = player.find_all('td')[0].get_text(strip=True)\n",
    "            name = player.find_all('td')[1].find('a').get_text(strip=True)\n",
    "            position = player.find_all('td')[3].get_text(strip=True)\n",
    "            nationality = player.find_all('td')[2].get_text(strip=True)\n",
    "\n",
    "            # Scrape player height from profile page\n",
    "            try:\n",
    "                link = player.find('a').get('href')\n",
    "                full_link = base_url + link\n",
    "                response = requests.get(full_link)\n",
    "                profile_soup = BeautifulSoup(response.content, 'html.parser')\n",
    "                profile_table = profile_soup.find('tbody')\n",
    "                height_row = profile_table.find_all('tr')[2]\n",
    "                height = height_row.find_all('td')[1].get_text(strip=True).split()[0]\n",
    "            except AttributeError as e:\n",
    "                print(f\"❌ Error retrieving player information from page {player['detail_URL']}: {e}\")\n",
    "            player_data.append([dressnumber, name, position, nationality, height])\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error scraping player information: {e}\")\n",
    "\n",
    "    print(\"✅ Player data has been extracted\")\n",
    "    \n",
    "    # Save scraped data to csv file\n",
    "    with open('player_data.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Dressnumber', 'Name', 'Position', 'Nationality', 'Height'])\n",
    "        writer.writerows(player_data)\n",
    "    \n",
    "    print(\"✅ Player data has been saved to 'player_data.csv'\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error finding or clicking on the roster link: {e}\")\n",
    "\n",
    "# Ensure that driver gets quittetd even if exception occurs\n",
    "finally:\n",
    "    driver.quit()\n",
    "    print(\"✅ Webdriver has been quitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ccb30-9405-4f69-9544-1ed1f84d078c",
   "metadata": {},
   "source": [
    "### 4. Abgleich der DFs und Bereinigen der Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f0f76a-7adf-459f-bd22-4b6f07764cc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d64e4936-9e65-4c8b-a83a-94e87e117f9f",
   "metadata": {},
   "source": [
    "# Ressourcen & Source-Docs\n",
    "\n",
    "## Selenium\n",
    "1. [WebDriver](https://www.geeksforgeeks.org/selenium-webdriver-commands/)\n",
    "2. [Implizites und explizites Warten](https://www.geeksforgeeks.org/explicit-waits-in-selenium-python/)\n",
    "3. [ActionChains](https://www.geeksforgeeks.org/action-chains-in-selenium-python/)\n",
    "4. [element_to_be_clickable](https://selenium-python.readthedocs.io/api.html#module-selenium.webdriver.support.expected_conditions)\n",
    "5. [move_to_element](https://www.geeksforgeeks.org/move_to_element-method-action-chains-in-selenium-python/?ref=rp)\n",
    "\n",
    "## Beautiful Soup 4\n",
    "1. [Selenium: page_source](https://www.geeksforgeeks.org/page_source-driver-method-selenium-python/)\n",
    "2. [Beautiful Soup: find_all() & access links](https://beautiful-soup-4.readthedocs.io/en/latest/#making-the-soup:~:text=One%20common%20task%20is%20extracting%20all%20the%20URLs%20found%20within%20a%20page%E2%80%99s%20%3Ca%3E%20tags%3A)\n",
    "3. [Beautiful Soup: get_text()](https://beautiful-soup-4.readthedocs.io/en/latest/#get-text)\n",
    "4. [Requests: request.get()](https://docs.python-requests.org/en/latest/user/quickstart/)\n",
    "5. [Selenium: driver.quit()](https://www.geeksforgeeks.org/how-to-use-close-and-quit-method-in-selenium-python/)\n",
    "\n",
    "## Cleanup Code\n",
    "1. a\n",
    "2. b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a5179d-2fb5-4347-abd2-da813a46e408",
   "metadata": {},
   "source": [
    "# Challenges bei der Implementierung\n",
    "\n",
    "\n",
    "#### Cesar Laura, Scraping\n",
    "- Generell war es am anfang etwas verwirrend wie ich mich in den extracted daten navigiere und auf die gewünschte Information zugreife\n",
    "\n",
    "#### Dilly Julian\n",
    "-\n",
    "-\n",
    "\n",
    "#### Ecker Annina, Implementierung von Selenium:\n",
    "- Zunächst hatte ich Probleme mit dem WebDriver, da ich nicht die `headless`-Variante kannte. Da ich dann zusätzlich wegen dem Cookie-Banner etwas unsicher war, und ob der WebDriver damit immer gut umgehen würde, habe ich mich auch bei der `headless`-Option dazu entschieden, den Cookie-Banner wegklicken zu lassen.\n",
    "- Die Navigation zu den Menü-Items war grundsätzlich kein Problem, aber es gab einige Eigenschaften bei `element_to_be_clickable` wie das _implicite_ oder _explicite Wait_, wo ich mich einlesen musste."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
